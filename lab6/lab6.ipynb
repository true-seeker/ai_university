{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn import metrics\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.cluster import DBSCAN, KMeans\n",
    "from sklearn.linear_model import LinearRegression, Lasso, Ridge\n",
    "from sklearn.linear_model import LassoCV\n",
    "from matplotlib import pyplot as plt\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from catboost import CatBoostRegressor\n",
    "from sklearn.metrics import silhouette_score, davies_bouldin_score,v_measure_score\n",
    "from sklearn.mixture import GaussianMixture\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "df = pd.read_csv('../data/diamonds.csv')\n",
    "df"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "df2 = df.drop('id', axis=1)\n",
    "df2 = pd.get_dummies(df2, columns=[\"cut\", 'color', 'clarity'])\n",
    "df2"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "for i in df2.loc[:, df2.columns != 'price']:\n",
    "    df2[i] = df2[i] / max(df2[i])\n",
    "df2"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(nrows=3, ncols=3, figsize=(15, 10))\n",
    "for idx, feature in enumerate(df.columns[1:7].append(df.columns[8:])):\n",
    "    df.plot(feature, \"price\", subplots=True, kind=\"scatter\", ax=axes[idx // 3, idx % 3])"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "X = df2.loc[:, df2.columns != 'price']\n",
    "y = df2.loc[:, df2.columns == 'price']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "model_LR = LinearRegression()\n",
    "model_LR.fit(X_train, y_train)\n",
    "\n",
    "for i, j in zip(X.columns, *model_LR.coef_):\n",
    "    print(i, j)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "model_ridge = Ridge()\n",
    "model_ridge.fit(X_train, y_train)\n",
    "\n",
    "for i, j in zip(X.columns, *model_ridge.coef_):\n",
    "    print(i, j)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "model_lasso = Lasso()\n",
    "model_lasso.fit(X_train, y_train)\n",
    "\n",
    "for i, j in zip(X.columns, model_lasso.coef_):\n",
    "    print(i, j)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Инициализируем модель решающего дерева\n",
    "model = DecisionTreeClassifier(random_state=42,\n",
    "                               # функция для impurity ('gini' или 'entropy')\n",
    "                               criterion='gini',\n",
    "                               # максимальная глубина дерева +5-5\n",
    "                               max_depth=10,\n",
    "                               # минимальное число элементов в узле для разбиения (может быть долей)\n",
    "                               min_samples_split=5,\n",
    "                               # минимальное число элементов в листе (может быть долей)\n",
    "                               min_samples_leaf=5,\n",
    "                               # Минимальное значение дельты impurity\n",
    "                               # min_impurity_decrease=0,\n",
    "                               # веса для классов (можно дополнительно штрафовать за ошибку в нужных классах).\n",
    "                               # Поддерживает опцию 'balanced'.\n",
    "                               class_weight=None\n",
    "                               )\n",
    "\n",
    "# Обучаем модель\n",
    "model.fit(X_train, y_train)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "pd.DataFrame({'feature': df2.loc[:, df2.columns != 'price'].columns,\n",
    "              'importance': model.feature_importances_}).sort_values('importance', ascending=False)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "y_pred_train = model.predict(X_train)\n",
    "y_pred_test = model.predict(X_test)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "conf_mat = metrics.confusion_matrix(y_test, y_pred_test)\n",
    "conf_mat"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "rf = RandomForestRegressor(random_state=0)\n",
    "cb = CatBoostRegressor()\n",
    "\n",
    "rf.fit(X_train,y_train)\n",
    "cb.fit(X_train,y_train)\n",
    "\n",
    "predict_rf = rf.predict(X_test)\n",
    "predict_cb = cb.predict(X_test)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "cluster_tags=df2.columns"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "t = 20 #Перебор количества кластеров\n",
    "# создадим пустой список для записи показателя WCSS (нашей ошибки)\n",
    "wcss = []\n",
    "X= df2[cluster_tags]\n",
    "for i in range(1, t):\n",
    "\n",
    "    kmeans = KMeans(n_clusters = i, init = 'k-means++', max_iter = 2000, n_init = 10, random_state = 42)\n",
    "    kmeans.fit(X)\n",
    "\n",
    "    # для каждого кластера рассчитаем ошибку (атрибут inertia_) и поместим в список\n",
    "    wcss.append(kmeans.inertia_)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "plt.figure(figsize = (10,6))\n",
    "plt.plot(range(1, t), wcss)\n",
    "\n",
    "plt.title('Выбор количества кластеров методом локтя')\n",
    "plt.xlabel('Количество кластеров')\n",
    "plt.ylabel('WCSS')"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "km_scores= []\n",
    "km_silhouette = []\n",
    "vmeasure_score =[]\n",
    "db_score = []\n",
    "X_scaled=X.copy()\n",
    "for i in range(2,t):\n",
    "    km = KMeans(n_clusters=i, random_state=0).fit(X_scaled)\n",
    "    preds = km.predict(X_scaled)\n",
    "\n",
    "    print(\"Score for number of cluster(s) {}: {}\".format(i,km.score(X_scaled)))\n",
    "    km_scores.append(-km.score(X_scaled))\n",
    "\n",
    "    silhouette = silhouette_score(X_scaled,preds)\n",
    "    km_silhouette.append(silhouette)\n",
    "    print(\"Silhouette score for number of cluster(s) {}: {}\".format(i,silhouette))\n",
    "\n",
    "    db = davies_bouldin_score(X_scaled,preds)\n",
    "    db_score.append(db)\n",
    "    print(\"Davies Bouldin score for number of cluster(s) {}: {}\".format(i,db))\n",
    "\n",
    "    # v_measure = v_measure_score(y,preds)\n",
    "    # vmeasure_score.append(v_measure)\n",
    "    # print(\"V-measure score for number of cluster(s) {}: {}\".format(i,v_measure))\n",
    "    print(\"-\"*100)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "plt.figure(figsize=(7,4))\n",
    "plt.title(\"The elbow method for determining number of clusters\\n\",fontsize=16)\n",
    "plt.scatter(x=[i for i in range(2,t)],y=km_scores,s=150,edgecolor='k')\n",
    "plt.grid(True)\n",
    "plt.xlabel(\"Number of clusters\",fontsize=14)\n",
    "plt.ylabel(\"K-means score\",fontsize=15)\n",
    "plt.xticks([i for i in range(2,t)],fontsize=14)\n",
    "plt.yticks(fontsize=15)\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "plt.figure(figsize=(7,4))\n",
    "plt.title(\"The silhouette coefficient method \\nfor determining number of clusters\\n\",fontsize=16)\n",
    "plt.scatter(x=[i for i in range(2,t)],y=km_silhouette,s=150,edgecolor='k')\n",
    "plt.grid(True)\n",
    "plt.xlabel(\"Number of clusters\",fontsize=14)\n",
    "plt.ylabel(\"Silhouette score\",fontsize=15)\n",
    "plt.xticks([i for i in range(2,t)],fontsize=10)\n",
    "plt.yticks(fontsize=15)\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "plt.scatter(x=[i for i in range(2,t)],y=db_score,s=150,edgecolor='k')\n",
    "plt.grid(True)\n",
    "plt.xlabel(\"Davies-Bouldin score\")\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BIC for number of cluster(s) 3: -4917081.732864491\n",
      "Log-likelihood score for number of cluster(s) 3: 45.70209224740143\n",
      "----------------------------------------------------------------------------------------------------\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[27], line 5\u001B[0m\n\u001B[1;32m      3\u001B[0m gm_score\u001B[38;5;241m=\u001B[39m[]\n\u001B[1;32m      4\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m i \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mrange\u001B[39m(\u001B[38;5;241m2\u001B[39m,t):\n\u001B[0;32m----> 5\u001B[0m     gm \u001B[38;5;241m=\u001B[39m \u001B[43mGaussianMixture\u001B[49m\u001B[43m(\u001B[49m\u001B[43mn_components\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mi\u001B[49m\u001B[43m,\u001B[49m\u001B[43mn_init\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;241;43m10\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43mtol\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;241;43m1e-3\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43mmax_iter\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;241;43m2000\u001B[39;49m\u001B[43m)\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mfit\u001B[49m\u001B[43m(\u001B[49m\u001B[43mX_scaled\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m      6\u001B[0m     \u001B[38;5;28mprint\u001B[39m(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mBIC for number of cluster(s) \u001B[39m\u001B[38;5;132;01m{}\u001B[39;00m\u001B[38;5;124m: \u001B[39m\u001B[38;5;132;01m{}\u001B[39;00m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;241m.\u001B[39mformat(i,gm\u001B[38;5;241m.\u001B[39mbic(X_scaled)))\n\u001B[1;32m      7\u001B[0m     \u001B[38;5;28mprint\u001B[39m(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mLog-likelihood score for number of cluster(s) \u001B[39m\u001B[38;5;132;01m{}\u001B[39;00m\u001B[38;5;124m: \u001B[39m\u001B[38;5;132;01m{}\u001B[39;00m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;241m.\u001B[39mformat(i,gm\u001B[38;5;241m.\u001B[39mscore(X_scaled)))\n",
      "File \u001B[0;32m~/PycharmProjects/ai_university/venv/lib/python3.10/site-packages/sklearn/mixture/_base.py:186\u001B[0m, in \u001B[0;36mBaseMixture.fit\u001B[0;34m(self, X, y)\u001B[0m\n\u001B[1;32m    160\u001B[0m \u001B[38;5;250m\u001B[39m\u001B[38;5;124;03m\"\"\"Estimate model parameters with the EM algorithm.\u001B[39;00m\n\u001B[1;32m    161\u001B[0m \n\u001B[1;32m    162\u001B[0m \u001B[38;5;124;03mThe method fits the model ``n_init`` times and sets the parameters with\u001B[39;00m\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m    183\u001B[0m \u001B[38;5;124;03m    The fitted mixture.\u001B[39;00m\n\u001B[1;32m    184\u001B[0m \u001B[38;5;124;03m\"\"\"\u001B[39;00m\n\u001B[1;32m    185\u001B[0m \u001B[38;5;66;03m# parameters are validated in fit_predict\u001B[39;00m\n\u001B[0;32m--> 186\u001B[0m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mfit_predict\u001B[49m\u001B[43m(\u001B[49m\u001B[43mX\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43my\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    187\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\n",
      "File \u001B[0;32m~/PycharmProjects/ai_university/venv/lib/python3.10/site-packages/sklearn/mixture/_base.py:252\u001B[0m, in \u001B[0;36mBaseMixture.fit_predict\u001B[0;34m(self, X, y)\u001B[0m\n\u001B[1;32m    249\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m n_iter \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mrange\u001B[39m(\u001B[38;5;241m1\u001B[39m, \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mmax_iter \u001B[38;5;241m+\u001B[39m \u001B[38;5;241m1\u001B[39m):\n\u001B[1;32m    250\u001B[0m     prev_lower_bound \u001B[38;5;241m=\u001B[39m lower_bound\n\u001B[0;32m--> 252\u001B[0m     log_prob_norm, log_resp \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_e_step\u001B[49m\u001B[43m(\u001B[49m\u001B[43mX\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    253\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_m_step(X, log_resp)\n\u001B[1;32m    254\u001B[0m     lower_bound \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_compute_lower_bound(log_resp, log_prob_norm)\n",
      "File \u001B[0;32m~/PycharmProjects/ai_university/venv/lib/python3.10/site-packages/sklearn/mixture/_base.py:309\u001B[0m, in \u001B[0;36mBaseMixture._e_step\u001B[0;34m(self, X)\u001B[0m\n\u001B[1;32m    293\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21m_e_step\u001B[39m(\u001B[38;5;28mself\u001B[39m, X):\n\u001B[1;32m    294\u001B[0m \u001B[38;5;250m    \u001B[39m\u001B[38;5;124;03m\"\"\"E step.\u001B[39;00m\n\u001B[1;32m    295\u001B[0m \n\u001B[1;32m    296\u001B[0m \u001B[38;5;124;03m    Parameters\u001B[39;00m\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m    307\u001B[0m \u001B[38;5;124;03m        the point of each sample in X.\u001B[39;00m\n\u001B[1;32m    308\u001B[0m \u001B[38;5;124;03m    \"\"\"\u001B[39;00m\n\u001B[0;32m--> 309\u001B[0m     log_prob_norm, log_resp \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_estimate_log_prob_resp\u001B[49m\u001B[43m(\u001B[49m\u001B[43mX\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    310\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m np\u001B[38;5;241m.\u001B[39mmean(log_prob_norm), log_resp\n",
      "File \u001B[0;32m~/PycharmProjects/ai_university/venv/lib/python3.10/site-packages/sklearn/mixture/_base.py:529\u001B[0m, in \u001B[0;36mBaseMixture._estimate_log_prob_resp\u001B[0;34m(self, X)\u001B[0m\n\u001B[1;32m    510\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21m_estimate_log_prob_resp\u001B[39m(\u001B[38;5;28mself\u001B[39m, X):\n\u001B[1;32m    511\u001B[0m \u001B[38;5;250m    \u001B[39m\u001B[38;5;124;03m\"\"\"Estimate log probabilities and responsibilities for each sample.\u001B[39;00m\n\u001B[1;32m    512\u001B[0m \n\u001B[1;32m    513\u001B[0m \u001B[38;5;124;03m    Compute the log probabilities, weighted log probabilities per\u001B[39;00m\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m    527\u001B[0m \u001B[38;5;124;03m        logarithm of the responsibilities\u001B[39;00m\n\u001B[1;32m    528\u001B[0m \u001B[38;5;124;03m    \"\"\"\u001B[39;00m\n\u001B[0;32m--> 529\u001B[0m     weighted_log_prob \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_estimate_weighted_log_prob\u001B[49m\u001B[43m(\u001B[49m\u001B[43mX\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    530\u001B[0m     log_prob_norm \u001B[38;5;241m=\u001B[39m logsumexp(weighted_log_prob, axis\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m1\u001B[39m)\n\u001B[1;32m    531\u001B[0m     \u001B[38;5;28;01mwith\u001B[39;00m np\u001B[38;5;241m.\u001B[39merrstate(under\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mignore\u001B[39m\u001B[38;5;124m\"\u001B[39m):\n\u001B[1;32m    532\u001B[0m         \u001B[38;5;66;03m# ignore underflow\u001B[39;00m\n",
      "File \u001B[0;32m~/PycharmProjects/ai_university/venv/lib/python3.10/site-packages/sklearn/mixture/_base.py:482\u001B[0m, in \u001B[0;36mBaseMixture._estimate_weighted_log_prob\u001B[0;34m(self, X)\u001B[0m\n\u001B[1;32m    471\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21m_estimate_weighted_log_prob\u001B[39m(\u001B[38;5;28mself\u001B[39m, X):\n\u001B[1;32m    472\u001B[0m \u001B[38;5;250m    \u001B[39m\u001B[38;5;124;03m\"\"\"Estimate the weighted log-probabilities, log P(X | Z) + log weights.\u001B[39;00m\n\u001B[1;32m    473\u001B[0m \n\u001B[1;32m    474\u001B[0m \u001B[38;5;124;03m    Parameters\u001B[39;00m\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m    480\u001B[0m \u001B[38;5;124;03m    weighted_log_prob : array, shape (n_samples, n_component)\u001B[39;00m\n\u001B[1;32m    481\u001B[0m \u001B[38;5;124;03m    \"\"\"\u001B[39;00m\n\u001B[0;32m--> 482\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_estimate_log_prob\u001B[49m\u001B[43m(\u001B[49m\u001B[43mX\u001B[49m\u001B[43m)\u001B[49m \u001B[38;5;241m+\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_estimate_log_weights()\n",
      "File \u001B[0;32m~/PycharmProjects/ai_university/venv/lib/python3.10/site-packages/sklearn/mixture/_gaussian_mixture.py:762\u001B[0m, in \u001B[0;36mGaussianMixture._estimate_log_prob\u001B[0;34m(self, X)\u001B[0m\n\u001B[1;32m    761\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21m_estimate_log_prob\u001B[39m(\u001B[38;5;28mself\u001B[39m, X):\n\u001B[0;32m--> 762\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43m_estimate_log_gaussian_prob\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m    763\u001B[0m \u001B[43m        \u001B[49m\u001B[43mX\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mmeans_\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mprecisions_cholesky_\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mcovariance_type\u001B[49m\n\u001B[1;32m    764\u001B[0m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/PycharmProjects/ai_university/venv/lib/python3.10/site-packages/sklearn/mixture/_gaussian_mixture.py:429\u001B[0m, in \u001B[0;36m_estimate_log_gaussian_prob\u001B[0;34m(X, means, precisions_chol, covariance_type)\u001B[0m\n\u001B[1;32m    427\u001B[0m     \u001B[38;5;28;01mfor\u001B[39;00m k, (mu, prec_chol) \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28menumerate\u001B[39m(\u001B[38;5;28mzip\u001B[39m(means, precisions_chol)):\n\u001B[1;32m    428\u001B[0m         y \u001B[38;5;241m=\u001B[39m np\u001B[38;5;241m.\u001B[39mdot(X, prec_chol) \u001B[38;5;241m-\u001B[39m np\u001B[38;5;241m.\u001B[39mdot(mu, prec_chol)\n\u001B[0;32m--> 429\u001B[0m         log_prob[:, k] \u001B[38;5;241m=\u001B[39m np\u001B[38;5;241m.\u001B[39msum(\u001B[43mnp\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43msquare\u001B[49m\u001B[43m(\u001B[49m\u001B[43my\u001B[49m\u001B[43m)\u001B[49m, axis\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m1\u001B[39m)\n\u001B[1;32m    431\u001B[0m \u001B[38;5;28;01melif\u001B[39;00m covariance_type \u001B[38;5;241m==\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mtied\u001B[39m\u001B[38;5;124m\"\u001B[39m:\n\u001B[1;32m    432\u001B[0m     log_prob \u001B[38;5;241m=\u001B[39m np\u001B[38;5;241m.\u001B[39mempty((n_samples, n_components))\n",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "source": [
    "gm_bic= []\n",
    "gm_score=[]\n",
    "for i in range(2,t):\n",
    "    gm = GaussianMixture(n_components=i,n_init=10,tol=1e-3,max_iter=2000).fit(X_scaled)\n",
    "    print(\"BIC for number of cluster(s) {}: {}\".format(i,gm.bic(X_scaled)))\n",
    "    print(\"Log-likelihood score for number of cluster(s) {}: {}\".format(i,gm.score(X_scaled)))\n",
    "    print(\"-\"*100)\n",
    "    gm_bic.append(-gm.bic(X_scaled))\n",
    "    gm_score.append(gm.score(X_scaled))\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "plt.figure(figsize=(7,4))\n",
    "plt.title(\"The Gaussian Mixture model BIC \\nfor determining number of clusters\\n\",fontsize=16)\n",
    "plt.scatter(x=[i for i in range(2,t)],y=np.log(np.abs(gm_bic)),s=150,edgecolor='k')\n",
    "plt.grid(True)\n",
    "plt.xlabel(\"Number of clusters\",fontsize=14)\n",
    "plt.ylabel(\"Log of Gaussian mixture BIC score\",fontsize=15)\n",
    "plt.xticks([i for i in range(2,t)],fontsize=14)\n",
    "plt.yticks(fontsize=15)\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "model_cluster_6 = KMeans(6)\n",
    "model_cluster_6.fit(X_scaled)\n",
    "y_pred_km_6 = model_cluster_6.predict(X_scaled)\n",
    "model_cluster_13 = KMeans(13)\n",
    "model_cluster_13.fit(X_scaled)\n",
    "y_pred_km_13 = model_cluster_13.predict(X_scaled)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "x6 = X_scaled['sqft_living']\n",
    "y6 = X_scaled['price']\n",
    "plt.figure(figsize=(20,10))\n",
    "plt.title(\"Визуализация кластеров\\n\",fontsize=16)\n",
    "plt.scatter(x=x6,y=y6,s=15,c=y_pred_km_6)\n",
    "plt.grid(True)\n",
    "plt.xlabel(\"Жилая площадь\",fontsize=14)\n",
    "plt.ylabel(\"Стоимость\",fontsize=15)\n",
    "plt.xticks(fontsize=14)\n",
    "plt.yticks(fontsize=15)\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "x6 = X_scaled['sqft_lot']\n",
    "y6 = X_scaled['price']\n",
    "plt.figure(figsize=(20,10))\n",
    "plt.title(\"Визуализация кластеров\\n\",fontsize=16)\n",
    "plt.scatter(x=x6,y=y6,s=15,c=y_pred_km_6)\n",
    "plt.grid(True)\n",
    "plt.xlabel(\"Общая площадь\",fontsize=14)\n",
    "plt.ylabel(\"Стоимость\",fontsize=15)\n",
    "plt.xticks(fontsize=14)\n",
    "plt.yticks(fontsize=15)\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "x13= X_scaled['sqft_lot']\n",
    "y13 = X_scaled['price']\n",
    "plt.figure(figsize=(20,10))\n",
    "plt.title(\"Визуализация кластеров\\n\",fontsize=16)\n",
    "plt.scatter(x=x13,y=y13,s=15,c=y_pred_km_13)\n",
    "plt.grid(True)\n",
    "plt.xlabel(\"Общая площадь\",fontsize=14)\n",
    "plt.ylabel(\"Стоимость\",fontsize=15)\n",
    "plt.xticks(fontsize=14)\n",
    "plt.yticks(fontsize=15)\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "model_dbscan = DBSCAN(eps=10000, min_samples=100)\n",
    "\n",
    "y_pred_dbscan = model_dbscan.fit_predict(X_scaled)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "xdbs= X_scaled['sqft_living']\n",
    "ydbs = X_scaled['price']\n",
    "plt.figure(figsize=(20,10))\n",
    "plt.title(\"Визуализация кластеров\\n\",fontsize=16)\n",
    "plt.scatter(x=xdbs,y=ydbs,s=15,c=y_pred_dbscan)\n",
    "plt.grid(True)\n",
    "plt.xlabel(\"Жилая площадь\",fontsize=14)\n",
    "plt.ylabel(\"Стоимость\",fontsize=15)\n",
    "plt.xticks(fontsize=14)\n",
    "plt.yticks(fontsize=15)\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "#Здесь фактическое шкалирование\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "mms = {}\n",
    "dfs = X_scaled.copy(deep=True)\n",
    "for c in X_scaled.columns:\n",
    "    mms[c] = MinMaxScaler().fit(dfs[c].values.reshape(-1,1))\n",
    "    dfs[c] = mms[c].transform(dfs[c].values.reshape(-1,1))\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "dfs"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "model_cluster_6 = KMeans(6)\n",
    "model_cluster_6.fit(dfs)\n",
    "y_pred_km_6 = model_cluster_6.predict(dfs)\n",
    "dfs['Кластер'] = kmeans.labels_"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "x6 = dfs['sqft_living']\n",
    "y6 = dfs['price']\n",
    "plt.figure(figsize=(20,10))\n",
    "plt.title(\"Визуализация кластеров\\n\",fontsize=16)\n",
    "plt.scatter(x=y6,y=x6,s=15,c=y_pred_km_6)\n",
    "plt.grid(True)\n",
    "plt.xlabel(\"Стоимость\",fontsize=14)\n",
    "plt.ylabel(\"Кластер\",fontsize=15)\n",
    "plt.xticks(fontsize=14)\n",
    "plt.yticks(fontsize=15)\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "dfs.loc[dfs['Кластер']==0].describe()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "model_dbscan_s = DBSCAN(eps=0.0001, min_samples=100)\n",
    "y_pred_dbscan_s = model_dbscan_s.fit_predict(dfs)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "model_dbscan_s.get_params()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "xdbs= dfs['sqft_living']\n",
    "ydbs = dfs['price']\n",
    "plt.figure(figsize=(20,10))\n",
    "plt.title(\"Визуализация кластеров\\n\",fontsize=16)\n",
    "plt.scatter(x=xdbs,y=ydbs,s=15,c=y_pred_dbscan_s)\n",
    "plt.grid(True)\n",
    "plt.xlabel(\"Жилая площадь\",fontsize=14)\n",
    "plt.ylabel(\"Стоимость\",fontsize=15)\n",
    "plt.xticks(fontsize=14)\n",
    "plt.yticks(fontsize=15)\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "km_scores= []\n",
    "km_silhouette = []\n",
    "vmeasure_score =[]\n",
    "db_score = []\n",
    "\n",
    "for i in range(2,t):\n",
    "    km = KMeans(n_clusters=i, random_state=0).fit(dfs)\n",
    "    preds = km.predict(dfs)\n",
    "\n",
    "    print(\"Score for number of cluster(s) {}: {}\".format(i,km.score(dfs)))\n",
    "    km_scores.append(-km.score(dfs))\n",
    "\n",
    "    silhouette = silhouette_score(dfs,preds)\n",
    "    km_silhouette.append(silhouette)\n",
    "    print(\"Silhouette score for number of cluster(s) {}: {}\".format(i,silhouette))\n",
    "\n",
    "    db = davies_bouldin_score(dfs,preds)\n",
    "    db_score.append(db)\n",
    "    print(\"Davies Bouldin score for number of cluster(s) {}: {}\".format(i,db))\n",
    "\n",
    "#    v_measure = v_measure_score(y,preds)\n",
    "#    vmeasure_score.append(v_measure)\n",
    "#    print(\"V-measure score for number of cluster(s) {}: {}\".format(i,v_measure))\n",
    "    print(\"-\"*100)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "plt.figure(figsize=(7,4))\n",
    "plt.title(\"The elbow method for determining number of clusters\\n\",fontsize=16)\n",
    "plt.scatter(x=[i for i in range(2,t)],y=km_scores,s=150,edgecolor='k')\n",
    "plt.grid(True)\n",
    "plt.xlabel(\"Number of clusters\",fontsize=14)\n",
    "plt.ylabel(\"K-means score\",fontsize=15)\n",
    "plt.xticks([i for i in range(2,t)],fontsize=14)\n",
    "plt.yticks(fontsize=15)\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "plt.figure(figsize=(7,4))\n",
    "plt.title(\"The silhouette coefficient method \\nfor determining number of clusters\\n\",fontsize=16)\n",
    "plt.scatter(x=[i for i in range(2,t)],y=km_silhouette,s=150,edgecolor='k')\n",
    "plt.grid(True)\n",
    "plt.xlabel(\"Number of clusters\",fontsize=14)\n",
    "plt.ylabel(\"Silhouette score\",fontsize=15)\n",
    "plt.xticks([i for i in range(2,t)],fontsize=10)\n",
    "plt.yticks(fontsize=15)\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "plt.scatter(x=[i for i in range(2,t)],y=db_score,s=150,edgecolor='k')\n",
    "plt.grid(True)\n",
    "plt.xlabel(\"Davies-Bouldin score\")\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "model_cluster_8 = KMeans(8)\n",
    "model_cluster_8.fit(dfs)\n",
    "y_pred_km_8 = model_cluster_8.predict(dfs)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "x13= dfs['sqft_living']\n",
    "y13 = dfs['price']\n",
    "plt.figure(figsize=(20,10))\n",
    "plt.title(\"Визуализация кластеров\\n\",fontsize=16)\n",
    "plt.scatter(x=x13,y=y13,s=15,c=y_pred_km_8)\n",
    "plt.grid(True)\n",
    "plt.xlabel(\"Жилая площадь\",fontsize=14)\n",
    "plt.ylabel(\"Стоимость\",fontsize=15)\n",
    "plt.xticks(fontsize=14)\n",
    "plt.yticks(fontsize=15)\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
